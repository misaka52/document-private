[TOC]

## 总结
### 1. 背景

#### 1.1 RocketMQ背景

RocketMQ，阿里巴巴自主研发的中间件，抗住了淘宝双十一的压力，现已捐献给apache

#### 1.2 引入原因

MQ消息队列，引入的原因

- 解耦：降低系统耦合性，减少强依赖
- 异步：减少非同步调用的处理时间
- 削峰：能抗住海量请求，并且消费端依然以固定速率消费

为何引入RocketMQ

- 吞吐量较大
- 开源，主要由Java语言开发，方便阅读排查问题
- 有强大的控制台界面，可创建topic、查询topic消息积压、查询单个消息
- 支持消息大量堆积
- 功能比较丰富：可发送同步消息、异步消息、单向消息、顺序消息、事务消息、批次消息
- 生产者、消费者提供失败重试功能

#### 1.3 包含角色

NameServer：路由注册中心，节点无状态，不相互通信

broker：消息服务器，负责消息存储、转发。每个broker与所有的NameServer建立长连接，每30s发送心跳信息

producer：消息生产者，通过NameServer获取broker路由信息，发送消息给broker

consumer：消息消费者，通过NameServer获取broker路由信息，从broker拉取消息消费，存在pull和push两种模式

### 2. NameServer

#### 2.1 架构

每个NameServer与所有Broker建立长连接，Broker每隔30s发送心跳包给NameServer来更新路由信息

producer首先与任意一个NameServer建立长连接，获取Topic路由信息。然后与向Topic提供服务的Master broker节点建立连接，且定时发送心跳消息，发送消息

consumer首先与任意一个NameServer建立长连接，获取Topic路由信息。然后与向Topic提供服务的Master、Slave broker节点建立连接，并定时发送心跳消息。消费者在向Master拉取消息，Master会根据拉取偏移量与最大偏移量的距离差，和从服务器是否可读等因素建议下一次拉取走Master还是Slave

#### 2.2 broker路由信息管理

**路由元信息**

- HashMap<String, List\<QueueDate>> topicQueueData：key-topic，value-消息队列
- HashMap<String, BrokerData>> brokerAddrData: key-brokerName, value-broker地址信息
- HashMap<String, Set\<String>> clusterAddrTable: key-clusterName, Set\<String> - brokerName集合
- HashMap<String, BrokerLiveInfo>> brokerLiveTable: key- brokerAddr, value- broker存活信息
- HashMap<String, List\<String>>: key-brokerAddr, value-filter server集合

路由注册：broker每隔30s向所有的Nameserver服务器发送心跳包，包含broker路由信息。

路由删除：NameServer每隔10s扫描一次，移除超过120s未更新的broker路由信息；broker正常关闭时也会发送请求，要求NameServer移除broker路由信息

路由发现：RocketMQ客户端发送路由信息不是实时的，当NameServer更新路由信息也不会主动通知客户端。客户端自己拉取最新路由信息

### 3. Producer发送消息

#### 3.1 消息发送类型

1. 同步消息：消息发送成功才返回。通过设置最大重试次数且retryAnotherBrokerWhenNotStoreOK=true来实现自动重试
2. 异步消息：消息发送即可，等待异步回调结果。不可重试
3. 单项消息：只需要发送消息，不关注结果

#### 3.2 生产者启动

clientId={clientIP}@{instance}[@{unitName}] (unitName不为空则拼接)

同一个消费者组下，通过clientId来标记生产者，负载均衡，一个生产者可订阅多个消息队列，一个消息队列只可以被一个生产者订阅。消息者消费消息队列类似于生产者

> 当clientId一致时，负载均衡会发生错误。可能两个相同clientId的消费者对应同一个消息队列，同时都消费该队列的消息，且出现队列无消费者。

#### 3.3 发送消息

1. 消息校验：topic长度<= 127; body小于4M
2. 获取topic路由信息：先从缓存获取，查不到再从NameServer中获取，更新缓存
3. 选择消息队列：若开启broker故障延迟机制（默认未开启，sendLatencyFaultEnable=true开启），选择一个正常的broker返回，且会对消息发送过长的broker开启一定的禁用期（消息发送时间越长的broker，禁用期越长）；若未开启，则轮询选择一个broker，自动避开上一个broker。
4. 发送消息。若消息发送结果不等于成功且retryAnotherBrokerWhenNotStoreOK=true，则重新发送，选择新消息队列

#### 3.4 批量消息发送

将同一主题的消息批量发送到服务端，不支持延迟消息；每个批次不大于1M；topic一致；waitStoreOk一致。

> waitStoreOk: message属性，仅当同步刷盘且waitStoreOk=true时 等待同步刷盘成功才返回保存消息成功。该属性保存在消息properties中，默认返回true

### 4. 消息存储

#### 4.1 存储文件

- CommitLog文件：保存二进制mq消息，包含mq消息+空白字符补位。以消息偏移量命名，长度20，前位补零。消息到达CommitLog文件后，ReputMessageService线程会将消息转发到ConsumeQueue和Index文件。每条消息前4字节存储消息大小，紧接着存储消息内容
- ConsumeQueue文件：消费队列文件，可查询topic对应消息队列的消费信息，提供按时间戳查询消息。该目录下一级目录为topic，二级目录为消息队列。每个消息仅保存 consumeOffset(8B)+size(4B)+tag hashCode(8B)
- Index文件：索引文件，可通过Msg key查询消息。分为三部分，header，hash槽（500万），index目录列表（2000万）
- abort文件：broker启动时创建，在broker正常关闭前删除。可用于判断broker是否属于正常关闭状态
- checkpoint文件：保存CommitLog文件、ConsumeQueue文件、Index文件的最后刷盘时间

#### 4.2 消息存储过程

1. 发送者发送消息后，保存消息。基本校验，非Master服务器不能存储消息；主题长度不大于255，属性长度不大于65535
2. 若消息的延迟等级大于0，则创建新消息topic=SCHEDULE_TOPIC_XXX，设置queueId，并将原消息topic和队列id存储消息属性中。其他属性与原消息一致，进行消息存储流程
3. 获取写入锁
4. 根据AppendMessageCallback组装保存到CommitLog的消息，创建全局消息唯一id=ip(4b)+port(4b)+消息偏移量(8b)，，消息暂存到内存ByteBuffer中
5. 根据保存到内存的结果（保存成功、文件剩余空间不足、消息过大等），处理，。释放锁
6. 将内存数据刷新到磁盘。同步刷盘直接保存到磁盘，当刷盘超时则返回FLUSH_DISK_TIMEOUT；异步刷盘则唤醒后台刷盘线程
7. 启动HA主从同步，仅当SYNC_MASTER模式下才会同步slave。当同步SLAVE超时时返回FLUSH_SLAVE_TIMEOUT，当slave不可用时返回SLAVE_NOT_AVAILABLE

#### 4.3 MapperFile

一个MappedFile类对应一个CommitLog文件。重要属性如下

- FlushedPosition: 已刷盘位置，之前位置的消息都已经保存到磁盘中
- commitPosition：当前文件提交指针。表示已提交到内存的位置
- writePosition：写指针位置

文件提交时，将commitPosition到writePosition的数据提交到内存中，并修改两个指针。然后通过刷盘机制将内存中数据刷新到磁盘中

#### 4.4 文件过期清理机制

文件默认保留72小时（现在broker会默认配置48小时），通过定时任务每10s触发一次，检查文件是否过期，当过期且满足以下条件之一的话便可以删除文件

- 在指定时间段内可以清理，默认在[4:00, 5:00) 
- 当磁盘空间不足可以清理
- 固定触发清理次数，默认配置20次。每触发该类型清理减少一次

### 5. 消息消费
> 在一个JVM中，每个客户端（生产者、消费者）都持有一个单独的MQClientInstance，MQClientInstance只会启动一次
>
> 每个MQClientInstance中包含一个PullMessageService（Runnable），负责循环拉取任务

消费模式
- 广播模式，同一个消费者组下，每个消息队列会被所有的消费者消息
- 集群模式，同一个消费者组下，所有消费者均摊消息队列

#### 5.1 长轮询模式实现push消费
消费者并没有真正实现push消费，而是消费者主动向broker拉取消息。通过长轮询机制，循环向消息服务器发起消息拉取请求，默认5s轮询一次。当没有消息时，则线程悬挂15s。

#### 5.2 消息队列负载均衡
1.PullRequest对象什么时候加入到PullRequestQueue以便唤醒PullMessageService？

答：RebalanceService每隔20s对所有主题进行队列重新分配。每次都会获取主题的消息队列信息，以及从broker获取最新的消费者，对消息队列、消费进行重新分配。若出现新的消费者，则创建PullRequest加入到PullRequestQueue，消费消息。每个消费者组每个消息队列只存在一个PullRequest

2.当出现新的消费者，如何进行负载均衡，使得新加入的消费消息队列消息？

答：每次进行负载均衡时都会从broker查询最新的消费者信息，并且对消费者、消息队列排序，重新分配。新加入的消费者也能被分配到

#### 5.3 消息拉取及消费过程
1. PullMessageService从pullRequestQueue中获取PullRequest消息拉取请求，每个消息队列一个（同一主题下）pullRequest。DefaultMQPushConsumer中，PullRequest默认拉取完一次且有数据则延迟pullInterval 毫秒进行下一次拉取（producer配置，默认0不延迟）；其他如找不到消息的情况，立即进行下一次拉取。
2. 创建拉取请求，从broker端查询消息，返回给消费者
3. 若找到消息，消费者将消息保存到processQueue，并创建消费请求到ConsumeMessageService线程池。并发类消费按照批次分多个消费请求ConsumeRequest；顺序消息不支持批次发送，不需要分批
4. 消费者进行消费消息，针对并发消费模式监听者，先拉取到的批量消息按照批次拆分成多个任务，每个任务执行，调用监听者消费函数，消费完成。若消息消费成功，更新broker中消息队列消息偏移量；若消费失败，广播模式下直接删除消息，集群模式下回调broker，保存重试消息。当消息重试次数大于最大重试次数投递死信队列，否则投递重试队列
5. 对于投递重试队列的消息，将原topic保存到属性RETRY_TOPIC，topic改为%RETRY%{consumeGroup}，异步保存到commitLog文件中。消息存储参考4.2


#### 5.4 定时消息
1. 消息消费者接受消息时，若消息延迟级别大于0，则更改消息主题为SCHEDULE_TOPIC_XXX，queueId为延迟级别-1
2. 将原消息的topic、queueId保存到新消息的主题里，其他属性与原消息一致
3. 将消息保存到commitLog中。根据延迟队列建立相应的定时任务，定时任务启动时默认延迟1s后第一次启动（第一次查询不到再建立延迟指定时间的定时任务），第二次再延迟相应时间执行
4. 定时执行时通过延迟等级和topic获取消息队列，再从消息队列中查找指定offset获取消息大小，最后通过offset和消息大小从commitLog中查询消息
5. 根据查询到的延迟消息新建消息，恢复其topic和queueId，请求delay等级，保留其他信息（重试次数保留了），将该消息保存到commitLog中，等待消费者拉取

> 当消息消费失败时，消息主题会变成%RETRY%{consumerGroup}，并将原消息主题存储消息属性'RETRY_TOPIC'中

定时消息的扫描

1. broker启动，每个消息队列都会新增一个任务，用来扫描该队列下的定时消息。每个任务记录延迟等级和消费的偏移量
2. 任务运行时，通过延迟等级和最小偏移量获取一批消息，计算其投递时间，与当前时间对比
3. 若投递时间晚于当前时间，新增一个延迟时间（当前时间和投递时间的差值）的任务，本次任务结束
4. 若投递时间早于当前时间，将延迟消息还原并投递。继续计算下一个消息
5. 最终一批消息消费结束后，新增一个延迟时间为100ms的延迟任务，继续扫描定时消息

> 首次添加的任务延迟时间为1000ms。当任务出现异常或投递消息失败后，新增延迟时间为10000ms的任务

#### 5.5 消息消费重试
1. 消费者自动订阅了该组的重试消息主题(%RETRY%+consumerGroup)
2. 当消息消费失败时，消息被封装为重试消息 %RETRY%+consumeGroup，将原topic保存在RETRY_TOPIC属性中
3. 消息保存到commitlog中，当判断消息的延迟等级大于0，则将消息封装为定时消息SCHDULE_TOPIC_XXXX，将该重试消息的主题和队列id保存在属性REAL_TOPIC和REAL_QID中。等待定时消费
4. 当定时拉取到定时消息后，将定时消息恢复为原消息（重试消息）进行消费。消费者拉取

## 配置文件

```conf
brokerClusterName = DefaultCluster
brokerName = broker-a
# brokerId，表示master
brokerId = 0
# commitlog文件清理时间，04表示凌晨4点到5点
deleteWhen = 04
# commitlog文件保存时间
fileReservedTime = 48
# broker主从同步机制。SYNC_MASTER表示消息保存到master后并实时同步到slave，同步成功才表示消息保存成功
brokerRole = ASYNC_MASTER
# 刷盘机制
flushDiskType = ASYNC_FLUSH
```

## 疑问

1. CommitLog怎么存储消息？怎么查找消息？消息是否都用空白补位？顺序保存所有消息，前四字节为commitLog消息大小。可以通过offset查询。commitLog只有在最后不足保存一个消息时，才会使用空白补位
2. 消息重试时，设置topic为%RETRY%{consumeGroup}，原topic保存在属性中，后续什么时候恢复topic？这么设计意义是什么？失败重试的topic保存时统一保存为%RETRY%{consumeGroup}，用来标记重试topic，不会再恢复原topic
3. IndexFile文件存储探究。依次顺序保存IndexHeader（40字节）、槽（500万个，每个槽4字节，保存当前槽最新index索引）、索引列表（2000个索引，每个索引20字节）。当新增key时，增加一条索引条目，顺序追加到索引列表中，根据hashCode选择槽，槽中记录改槽对应的index的索引（其实是序号，index条目按照顺序存放）
4. CommitLog#根据偏移量和消息大小查询消息，CommitLog中消息体前4字节就是消息大小，为何还要单独传size？可以不传
5. PullRequest初始创建及合适加入线程池?RebalanceService每隔20s进行一次rebalance，每次都会查询该主题下所有消息队列和对应的消费者，对二者进行排序，重新分配消息队列，每个消息队列对应一个PullRequest
6. 批量消费时，若消费一定数据后中断，能否部分提交，不在消费已消费的数据？目前没有解决方案，程序应具有幂等性，可以正常处理这些重复数据
7. 集群模式使用broker存储offset，CONSUME_FROM_LAST_OFFSET和CONSUME_FROM_FIRST_OFFSET有什么区别，不都能拉倒offset吗？
8. 同一个消费者组，一个jvm上只能启动一个同名消费者组。且同一消费者组下的消费者，订阅的topic和tag必须完全一致，否则会出现消费紊乱的情况（尝试启动两个jvm程序，同一消费者组下，分别订阅不同的topic，造成两个应用各有一半消息丢失，因为共用了一个offset，offset与groupName有关）。一个消费者组可以同时订阅多个topic，只要保证消费者组下订阅的topic和tag一致即可
9. MsgOffsetId，MsgQuiqueId？
   1. MsgQuiqueId：producer端生成的id，保存在消息属性的UNIQUE_KEY中，由ip+进程号+classLoader.hashCode +jvm启动时间+计数器自增数量。通过控制台查询时，得到的Message ID就是值这个属性，更具msgId查询时，必须选择对应的topic或重试topic。后续每个重试消息的uniqueId都相同
   2. MsgOffsetId：即msgId，broker端保存消息时生成的消息id，在broker端具有全局唯一性。每个重试消息id不一致，使用这个id查询时，无需选择对应topic（随便选一个topic即可）。消息=broker ip（8B）+消息物理偏移量（8B）


## 应用
### 1.使用rocketmq注意事项
1. 开启日志：mq单条消费时间、观测消费速率
2. mq全局异常捕获处理，未处理会被当成消费失败